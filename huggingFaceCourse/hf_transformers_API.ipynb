{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Inference with API Requests\n",
    "\n",
    "* The first step is to choose which model we are going to run. \n",
    "* Go to the Model Hub <https://huggingface.co/models> and select the model you want to use. \n",
    "* If you are unsure where to start, make sure to check our recommended models for each NLP task available.\n",
    "\n",
    "ENDPOINT = https://api-inference.huggingface.co/models/<MODEL_ID>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREREQUISITES\n",
    "import json\n",
    "import requests\n",
    "import yaml\n",
    "\n",
    "with open(\"configs.yml\", 'r') as ymlfile:\n",
    "    cfg = yaml.safe_load(ymlfile)\n",
    "\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/gpt2\"\n",
    "headers = {\"Authorization\": f\"Bearer {cfg['api_creds']['API_TOKEN']}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using **gpt2** as an example in this notebook. To run inference, we simply use this code:\n",
    "\n",
    "def query(payload):\n",
    "    data = json.dumps(payload)\n",
    "    response = requests.request(\"POST\", API_URL, headers=headers, data=data)\n",
    "    return json.loads(response.content.decode(\"utf-8\"))\n",
    "\n",
    "data = query(\"Can you please let us know more details about your \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': \"Can you please let us know more details about your iphone if you have any other iphone that comes with this feature?\\n\\n\\nHi, we can't wait to see you soon!\\n\\n\\nAs mentioned in the last thread, this\"}]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test: Zero-shot classification task\n",
    "\n",
    "This task is a super useful to try it out classification with zero code, you simply pass a sentence/paragraph and the possible labels for that sentence and you get a result.\n",
    "\n",
    "Recommended model: facebook/bart-large-mnli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request:\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/facebook/bart-large-mnli\"\n",
    "\n",
    "def query(payload):\n",
    "    data = json.dumps(payload)\n",
    "    response = requests.request(\"POST\", API_URL, headers=headers, data=data)\n",
    "    return json.loads(response.content.decode(\"utf-8\"))\n",
    "\n",
    "# When sending your request, you should send a JSON encoded payload. Here are all the options\n",
    "data = query(\n",
    "    {\n",
    "        \"inputs\": [\n",
    "            \"At the current moment, i do no think the report is updated to include all client facing work. I have not checked in the last week but the last time I checked, some of my attainable metric was not accurate.\",\n",
    "            \"Getting numbers into the system earlier in the year would be great...always feels like we are playing catchup throughout the first quarter.\"],\n",
    "        \"parameters\": {\"candidate_labels\": [\"bug\", \"feature request\", \"kudos\"]},\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of dictionaries in this examle: \n",
      " [\n",
      "    {\n",
      "        \"sequence\": \"At the current moment, i do no think the report is updated to include all client facing work. I have not checked in the last week but the last time I checked, some of my attainable metric was not accurate.\",\n",
      "        \"labels\": [\n",
      "            \"bug\",\n",
      "            \"kudos\",\n",
      "            \"feature request\"\n",
      "        ],\n",
      "        \"scores\": [\n",
      "            0.47472214698791504,\n",
      "            0.27305641770362854,\n",
      "            0.2522214651107788\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"sequence\": \"Getting numbers into the system earlier in the year would be great...always feels like we are playing catchup throughout the first quarter.\",\n",
      "        \"labels\": [\n",
      "            \"feature request\",\n",
      "            \"bug\",\n",
      "            \"kudos\"\n",
      "        ],\n",
      "        \"scores\": [\n",
      "            0.6460283994674683,\n",
      "            0.21182933449745178,\n",
      "            0.14214220643043518\n",
      "        ]\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Return value is either a dict or a list of dicts if you sent a list of inputs\n",
    "print(\"List of dictionaries in this examle: \\n\", json.dumps(data, indent=4, sort_keys=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a481908efc976352568051b9ddcf43a247bdd059f95919b3c0880bc73d24bc6f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('3.8.5': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
